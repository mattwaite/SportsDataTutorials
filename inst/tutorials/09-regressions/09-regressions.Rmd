---
title: "Sports Data Lesson 9: Correlations and regressions"
output: 
  learnr::tutorial:
    progressive: true
    allow_skip: true
    theme: united
    ace_theme: github
runtime: shiny_prerendered
description: >
  Learn how to see how related two numbers are and make a model.
---

```{r setup, include=FALSE}
library(learnr)
library(gradethis)
library(tidyverse)
library(glue)
knitr::opts_chunk$set(echo = FALSE)
tutorial_options(exercise.completion=FALSE)
```

# Correlations and regression

## The basics

Throughout sports, you will find no shortage of opinions. From people yelling at their TV screens to an entire industry of people paid to have opinions, there are no shortage of reasons why this team sucks and that player is great. They may have their reasons, but a better question is, does that reason really matter? 

Can we put some numbers behind that? Can we prove it or not? 

This is what we're going to start to answer. And we'll do it with correlations and regressions.

First, we need data from the most recent college football season. **For purposes of this exercise, you don't need to do this. The data is included here if you want to try this in your own notebook.**

```{r echo=FALSE, class.output="bg-info", results="asis",  message=FALSE,  warning=FALSE}
library(downloadthis)
library(glue)

dllink <- download_link(
  link = "https://mattwaite.github.io/sportsdatafiles/footballlogs23.csv",
  button_label = "Download csv file",
  button_type = "danger",
  has_icon = TRUE,
  icon = "fa fa-save",
  self_contained = FALSE
)

glue("<pre><p><strong>For this walkthrough:</strong></p><p>{dllink}</p></pre>")

```

Then load the tidyverse.

```{r load-tidyverse, exercise=TRUE}
library(tidyverse)
```
```{r load-tidyverse-solution}
library(tidyverse)
```
```{r load-tidyverse-check}
grade_this_code()
```

Now read in all FBS college football teams and their season stats. 

```{r correlations-load-data, message=FALSE, warning=FALSE}
correlations <- read_csv("https://mattwaite.github.io/sportsdatafiles/footballlogs23.csv")

newcorrelations <- correlations |>
  mutate(
    differential = TeamScore - OpponentScore
  )

coefficient <- cor.test(correlations$TeamScore, correlations$RushingYds)

newcoefficient <- cor.test(newcorrelations$differential, newcorrelations$RushingYds)

passcoefficient <- cor.test(newcorrelations$differential, newcorrelations$PassingYds)

fit <- lm(differential ~ RushingYds, data = newcorrelations)

pass <- lm(differential ~ PassingYds, data = newcorrelations)
```
```{r correlations-load-data-exercise, exercise = TRUE}
correlations <- read_csv("https://mattwaite.github.io/sportsdatafiles/footballlogs23.csv")
```
```{r correlations-load-data-exercise-solution}
correlations <- read_csv("https://mattwaite.github.io/sportsdatafiles/footballlogs23.csv")
```
```{r correlations-load-data-exercise-check}
grade_this_code()
```

How much, over the course of a season, does a thing matter? That's the question you're going to answer. 

In our case, we're going to return to Run the Damn Ball guy. How much does a team's rushing yards impact the number of points they score in a game? How much difference can we explain in points with rushing yards? 

We're going to use two different methods here and they're closely related. Correlations -- specifically the Pearson Correlation Coefficient -- is a measure of how related two numbers are in a linear fashion. In other words -- if our X value goes up one, what happens to Y? If it also goes up 1, that's a perfect correlation. X goes up 1, Y goes up 1. Every time. 

Correlation coefficients are a number between 0 and 1, with zero being no correlation and 1 being perfect correlation **if our data is linear**. We'll soon go over scatterplots to visually determine if our data is linear, but for now, we have a hypothesis: More rush yards, more points. Run. The. Damn. Ball. That is an argument for a linear relationship between them.

But is there one?

Let's first take a look at the data. 

```{r head-data, exercise=TRUE, exercise.setup = "correlations-load-data"}
head(____)
```
```{r head-data-solution}
head(correlations)
```
```{r head-data-check}
grade_this_code()
```

### Exercise 1: Correlating rushing yards and points.

In R, there is a `cor` function, and it works much the same as `mean` or `median`. So we want to see if `TeamScore` is correlated with `RushingYds`, which should be pretty self explanatory. We do that by referencing those two fields and specifying we want a `pearson` correlation. The number we get back is the correlation coefficient.

```{r correlation1, exercise=TRUE, exercise.setup = "correlations-load-data"}
____ |> 
  summarise(
    pearson = cor(TeamScore, ____, method="pearson")
    )
```
```{r correlation1-solution, exercise.reveal_solution = FALSE}
correlations |> 
  summarise(
    pearson = cor(TeamScore, RushingYds, method="pearson")
    )
```
```{r correlation1-check}
grade_this_code()
```

```{r cor1, exercise=FALSE, exercise.eval=TRUE, exercise.setup = "correlations-load-data", results='asis'}
glue("So on a scale of -1 to 1, where 0 means there's no relationship at all and 1 or -1 means a perfect relationship, penalty yards and whether or not the team scores more points than it give up are at {coefficient$estimate}. You could say they're {format(coefficient$estimate*100, digits=1)} percent related in the positive -- sometimes more rushing yards means more points, sometimes there's not. It's about the worst outcome for an argument -- it's 50-50.")
```

### Exercise 2: Correlating rushing yards and the point spread.

But, but, but, Run The Damn Ball Guy sputters, running the ball is about keeping it away from the other team as much as it's about scoring points. They can't score if they don't have the ball.

Fine, let's test this.

We're going to create a new dataframe called `newcorrelations` and in it, we need to mutate a new field called `differential`. The score differential is the point spread. I leave it to you to figure out how to calculate the point spread.

```{r correlation2, exercise=TRUE, exercise.setup = "correlations-load-data"}
____ <- correlations |>
  mutate(
    differential = ____ - ____
  )


____ |> 
  summarise(
    correlation = cor(differential, ____, method="pearson")
    )
```
```{r correlation2-solution, exercise.reveal_solution = FALSE}
newcorrelations <- correlations |>
  mutate(
    differential = TeamScore - OpponentScore
  )

newcorrelations |> 
  summarise(
    correlation = cor(differential, RushingYds, method="pearson")
    )
```
```{r correlation2-check}
grade_this_code()
```

```{r cor2, exercise=FALSE, exercise.eval=TRUE, exercise.setup = "correlations-load-data", results='asis'}
glue("Uh oh. Run The Damn Ball Guy's argument has gotten worse. The pearson correlation coefficient is even closer to 50-50 -- {format(newcoefficient$estimate, digits=1)} -- where there's a positive correlation here, but it's not perfect.")
```

Normally, at this point, you'd quit while you were ahead. Arguments with Run The Damn Ball Guy are, on a good day, an exercise in pounding your head against a rock. They have a world view and are going to stick with it, so bringing inconclusive evidence to a stupid fight is a waste of time. 

But, hope springs eternal and we want to show Mr. Guy that this is not a great argument in modern college football. 

Enter regression. Regression is how we try to fit our data into a line that explains the relationship the best. Regressions will help us predict things as well -- if we have a team that has so many rushing yards, what kind of point differential could we expect? So regressions are about prediction, correlations are about description. Correlations describe a relationship. Regressions help us predict what that relationship means and what it might look like in the real world. **Specifically, it tells us how much of the change in a dependent variable can be explained by the independent variable**.

Another thing regressions do is give us some other tools to evaluate if the relationship is real or not.

### Exercise 3: Using linear regressions for rushing yards

I assure you that Run The Damn Ball Guy doesn't know what a linear regression is, but let's use one to fight him. 

First things first, we're going to use newcorrelations like we did above. It has the point differential we used before. To do this, we're going to create a new object called fit -- named after the line of best fit, which is the regression line. It's going to use a new function -- `lm`. Then we need to say X is approximately modeled by Y. X will be our differential. Y will be the rushing yards. The approximately modeled by is the ~ character. In fact, that's how you read ~ in R. When you see ~, you can say "is approximately modeled by."

```{r regression1, exercise=TRUE, exercise.setup = "correlations-load-data"}
fit <- lm(____ ~ ____, data = newcorrelations)
summary(____)
```
```{r regression1-solution, exercise.reveal_solution = FALSE}
fit <- lm(differential ~ RushingYds, data = newcorrelations)
summary(fit)
```
```{r regression1-check}
grade_this_code()
```

There's three things we need here: 

First we want to look at the p-value. It's at the bottom right corner of the output. In the case of rushing yards, the p-value is <2.2e-16. Remember your exponential notation? That means the probability this relationship is just random noise is less than .00000000000000022. The threshold we're looking for here is .05. If it's less than .05, then the relationship is considered to be *statistically significant*. **Significance here does not mean it's a big deal. It means it's not random**. That's it. Just that. Not random. So in our case, the relationship between rushing yards and a team's aggregate point differential is **statistically significant**. The differences in score difference and rushing yards is not random. Run The Damn Ball Guy is excited by this, but as we'll see, he shouldn't be.

```{r rsquared1, exercise=FALSE, exercise.eval=TRUE, exercise.setup = "correlations-load-data", results='asis'}
glue("Second, we look at the Adjusted R-squared value. It's right above the p-value. Adjusted R-squared is a measure of how much of the difference between a teams point spread can be explained by rushing yards. Our correlation coefficient said they're 50 percent related to each other, but rushing yard's ability to explain the difference between point spreads in games? About {format(summary(fit)$r.squared*100, digits=1)} percent. That means we can explain {format(summary(fit)$r.squared*100, digits=1)} percent of the difference in score just by looking at a team's rushing yards. That's ... not super conclusive. It's not nothing, but it's not the clattering proof Run The Damn Ball Guy was looking for. Again, we should quit and do literally anything with our life other than talk to Run The Damn Ball Guy.")
```

```{r rsquared2, exercise=FALSE, exercise.eval=TRUE, exercise.setup = "correlations-load-data", results='asis'}
glue("The third thing we can look at, and we only bother if the first two are meaningful, is the coefficients. In the middle, you can see the (Intercept) is {fit$coefficients[1]} and the RushingYds coefficient is {fit$coefficients[2]}. Remember high school algebra? Remember learning the equation of a line? Remember swearing that learning `y=mx+b` is stupid because you'll never need it again? Surprise. It's useful again. In this case, we could try to predict a team's score differential in a game -- will they score more than they give up -- by using `y=mx+b`. In this case, y is the aggregate score, m is {fit$coefficients[2]} and b is {fit$coefficients[1]}. So we would multiply a teams total rushing yards by {fit$coefficients[2]} and then {fit$coefficients[1]} to it. The result would tell you what the total aggregate score in the game would be, according to our model. Chance that your even close with this? About {format(summary(fit)$r.squared*100, digits=1)} percent.")
```

```{r rsquared3, exercise=FALSE, exercise.eval=TRUE, exercise.setup = "correlations-load-data", results='asis'}
glue("What does that mean? Let's use a simple example. Let's say you rush for 100 yards. 100 * {format(fit$coefficients[2], digits=2)} is {format(fit$coefficients[2]*100, digits=2)}. So 100 yards of rushing gets you {format(fit$coefficients[2]*100, digits=1)} points ... until you factor in the intercept, which is {format(fit$coefficients[1], digits=2)} points. Meaning, according to our model, you rush for 100 yards, your score margin is {format((fit$coefficients[2]*100) + fit$coefficients[1], digits=1)}.")
```

You can see the problem in a graph. On the X axis is rushing yards, on the y is aggregate score. If these elements had a strong relationship, we'd see a clear pattern moving from right to left, sloping up. On the left would be the teams with few rushing yards and a negative point differential. On right would be teams with high rushing yards and positive point differentials. Do you see that below?

```{r correlationchart, exercise=FALSE, exercise.eval=TRUE, exercise.setup = "correlations-load-data"}
ggplot(newcorrelations, aes(x=RushingYds, y=differential)) + geom_point()
```

A charitable reading of this would be ... shrug? Maybe? Seems kind of random? And that's the point. It's squishy. 

## But what about passing the ball?

So we've **firmly** established that Run The Damn Ball Guy arguments are dumb. But is the Playstation Offense the answer? 

So instead of looking at rushing yards, let's look at passing yards. Can we do better looking at yards through the air?

### Exercise 4: A second correlation

The good news is that our newcorrelations dataframe has everything we need.

Just run your correlations like before, swapping out rushing yards for passing yards.

```{r regression2, exercise=TRUE, exercise.setup = "correlations-load-data"}
newcorrelations |> 
  summarise(correlation = cor(differential, ____, method="pearson"))
```
```{r regression2-solution, exercise.reveal_solution = FALSE}
newcorrelations |> 
  summarise(correlation = cor(differential, PassingYds, method="pearson"))
```
```{r regression2-check}
grade_this_code()
```

```{r cor3, exercise=FALSE, exercise.eval=TRUE, exercise.setup = "correlations-load-data", results='asis'}
glue("Answer: {format(newcoefficient$estimate*100, digits=1)} percent.
     
Oh no. That's way less correlated than rushing yards.")
```

### Exercise 5: A second regression

Let's see how predictive it is.

```{r regression3, exercise=TRUE, exercise.setup = "correlations-load-data"}
pass <- lm(differential ~ ____, data = newcorrelations)
summary(pass)
```
```{r regression3-solution, exercise.reveal_solution = FALSE}
pass <- lm(differential ~ PassingYds, data = newcorrelations)
summary(pass)
```
```{r regression3-check}
grade_this_code()
```

First we check p-value. Same as before: this is really, really, really not random. 

```{r rsquared4, exercise=FALSE, exercise.eval=TRUE, exercise.setup = "correlations-load-data", results='asis'}
glue("Second, Adjusted R-squared: {summary(pass)$r.squared}. With rushing yards, we could predict {format(summary(fit)$r.squared*100, digits=1)} percent of the variation between score margin by looking at a team's rushing yards. But with passing? A whopping {format(summary(pass)$r.squared*100, digits=1)} percent.")
```

Ohhh no. What have we done?

```{r rsquared5, exercise=FALSE, exercise.eval=TRUE, exercise.setup = "correlations-load-data", results='asis'}
glue("Third, the coefficients: In this case, our `y=mx+b` formula looks like `y = {format(pass$coefficients[2], digits=2)}x {pass$coefficients[1]}`. So if we were applying this, if our team passes for 250 yards, what happens?  

Your score margin is {format(pass$coefficients[2] * 250 + pass$coefficients[1], digits=2)}.

Chances of that being right? About {format(summary(pass)$r.squared*100, digits=1)} percent. Not good at all.
")
```

What does this all mean? It means a sport with 22 players on the field at any one time is much more complicated than simple arguments on message boards would lead you to believe.
